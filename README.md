# Adversarial Example Soups: Improving Transferability and Stealthiness for Free(TIFS 2025)

This is the code for the paper [Adversarial Example Soups: Improving Transferability and Stealthiness for Free](https://ieeexplore.ieee.org/document/10858076).

Notably, all baseline attack methods use official codes, and we appreciate the contributions of these authors to the research community of adversarial attacks.

For gradient stabilization attacks, the Code refers to: [Penelizing Gradient Norm Attack](https://github.com/Trustworthy-AI-Group/PGN) and [Spectrum Simulation Attack](https://github.com/yuyang-long/SSA).

For input transformation attacks, Code refer to: [Spectrum Simulation Attack](https://github.com/yuyang-long/SSA).

For Feature destruction attacks, Code refer to: [Neuron Attribution-Based Attacks](https://github.com/jpzhang1810/NAA).

For the formation of adversarial example soups, it is only necessary to average the images of multi-batche adversarial examples.

## Contact Us
If you have any problem with this work, please feel free to reach us at yangbo_hn@163.com

